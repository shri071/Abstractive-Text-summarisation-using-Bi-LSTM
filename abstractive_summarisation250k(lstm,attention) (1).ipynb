{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfjATcTRsYqg"
   },
   "source": [
    "# First we will import the bahdanau attention model from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E3EtN2iSqmrY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL6BmdMxsx0-"
   },
   "source": [
    "# Import all the important libraries required for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vp7N8fP1rBol"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed,Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf46LotptA1M"
   },
   "source": [
    "## The Dataset taken is from kaggle amazon fine food dataset.\n",
    "## The link for the kaggle data set:\n",
    " https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "### The Dataset contains Reviews and the Summaries. We will build a code wherein we will create our own summary in a way that it resembles very closely to the summary in the dataset and we will examine its the accuracy at output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxsDK27BrHjx",
    "outputId": "098428f6-3c06-4126-e3dc-e13e99c26c0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5N-io_t0utL-"
   },
   "source": [
    "The dataset contains over 500,000 reviews and we will only select 250,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i_pkEymgrkbZ"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('/content/drive/My Drive/dataset/Reviews.csv',nrows=250000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoxQuV-lu5jK"
   },
   "source": [
    "# Description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVuZPiJXsNc_",
    "outputId": "7c0317c9-d333-4ec4-bc66-a202a5a966f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "nE21xOhFsT7Z",
    "outputId": "78040bc0-b0c7-4322-fc1f-88f2d94195e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                                                                                                                                                                                     Text\n",
       "0   1  ...  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1   2  ...           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2   3  ...  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
       "3   4  ...  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
       "4   5  ...                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0h7zWwsCvhI8"
   },
   "source": [
    "# Cleaning and Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHX9SQ5yvw29"
   },
   "source": [
    "Performing basic preprocessing steps is very important before we get to the model building part. Using messy and uncleaned text data is a potentially disastrous move. So in this step, we will drop all the unwanted symbols, characters, etc. from the text that do not affect the objective of our problem.\n",
    "\n",
    "Here is the dictionary that we will use for expanding the contractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4cX8J5HKvntt"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AOQjpfav9FN"
   },
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "8.Remove short words\n",
    "\n",
    "Let’s define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99jQeRvXv_lD",
    "outputId": "c364ba3d-1af4-48c6-c3e1-7eaa4a0af1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ICAJYCqJ4Nwl"
   },
   "outputs": [],
   "source": [
    "data['Summary']=data['Summary'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PxCb8ofrwMyy"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wexiUkhVwZ3K"
   },
   "source": [
    "Preview of cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aL7fPZcGwZXG",
    "outputId": "cd767f88-144b-43e8-be08-6fa2f8de56b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YqkevcQm0DSh"
   },
   "outputs": [],
   "source": [
    "\n",
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1ZWX6cZ6mQ2",
    "outputId": "3598a5f9-31bb-4f73-91d7-6267ca55f5ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NNMVbIqj6oo3"
   },
   "outputs": [],
   "source": [
    "\n",
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ShtlI3u26q9G"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1xIqWVc4xHm"
   },
   "source": [
    "# Understanding the distribution of the sequences\n",
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "SskMbkBZwgj7",
    "outputId": "b78482f7-741c-4329-a901-63518a489323"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI84UW9o5JoE"
   },
   "source": [
    "We can fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
    "Let us understand the proportion of the length of summaries below 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKsI-LZZ1CiV",
    "outputId": "4fd5abb0-60c5-4b07-c11c-39f090211fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995836502662236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=20):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_E65PxN5U_6"
   },
   "source": [
    "We observe that 99% of the summaries have length below 20. So, we can fix maximum length of summary to 20.\n",
    "\n",
    "Let us fix the maximum length of review to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WMwRObAk5WB4"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_text_len=35\n",
    "max_summary_len=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2HV1YR35csy"
   },
   "source": [
    "\n",
    "Let us select the reviews and summaries whose length falls below or equal to max_text_len and max_summary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Rmb_wtKa5dW4"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVJzbNu45kRf"
   },
   "source": [
    "\n",
    "Remember to add the START and END special tokens at the beginning and end of the summary. Here, I have chosen sostok and eostok as START and END tokens\n",
    "\n",
    "Note: Be sure that the chosen special tokens never appear in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KGJ0jedN5l2d"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKkwNiBH6zgc"
   },
   "source": [
    "\n",
    "We are getting closer to the model building part. Before that, we need to split our dataset into a training and validation set. We’ll use 90% of the dataset as the training data and evaluate the performance on the remaining 10% (holdout set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "O4nrL03H61zg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oIHmBa-659L"
   },
   "source": [
    "# Preparing the Tokenizer\n",
    "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:\n",
    "\n",
    "# Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LwCV-9pl69me"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nNLSMD97CjN"
   },
   "source": [
    "\n",
    "Rarewords and its Coverage\n",
    "Let us look at the proportion rare words and its total coverage in the entire text\n",
    "\n",
    "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Gh3ZnT7DTJ",
    "outputId": "45fb157c-9ec3-4e93-e369-82ed97ec5acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 62.9958582604694\n",
      "Total Coverage of rare words: 1.3927535681449947\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdLeUg5A7Jnq"
   },
   "source": [
    "Remember:\n",
    "\n",
    "tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
    "\n",
    "cnt gives me the no. of rare words whose count falls below threshold\n",
    "\n",
    "tot_cnt - cnt gives me the top most common words\n",
    "\n",
    "Let us define the tokenizer with top most common words for reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X7wpSf327NAO"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcDM97_a7Pnn",
    "outputId": "92366bbf-3369-4264-9e20-abdf2afa61fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16083"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjSRArKP7V70"
   },
   "source": [
    "# Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ey8zFN7c7URW"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSWzppl57p0T"
   },
   "source": [
    "\n",
    "# Rarewords and its Coverage\n",
    "Let us look at the proportion rare words and its total coverage in the entire summary\n",
    "\n",
    "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1xvUCom7lgG",
    "outputId": "f0a878dd-d4b6-4b77-873b-c24a04233b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 73.28088217073473\n",
      "Total Coverage of rare words: 2.699530516431925\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6MvsVp_7xtn"
   },
   "source": [
    "\n",
    "Let us define the tokenizer with top most common words for summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mylxWx_m7ynA"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2C4LU-F73Dc"
   },
   "source": [
    "Let us check whether word count of start token is equal to length of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6UlVx2j73li",
    "outputId": "3d98c478-b5f7-42ff-e3b5-6ffca052eac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140674, 140674)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSAeXR3v78HC"
   },
   "source": [
    "Here, I am deleting the rows that contain only START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AFAUID_W78vW"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "tiyMuVP97_Ee"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXXHebB68BiC"
   },
   "source": [
    "\n",
    "# Model building\n",
    "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
    "\n",
    "### **Return Sequences** = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "\n",
    "### **Return State** = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "\n",
    "### **Initial State**: This is used to initialize the internal states of the LSTM for the first timestep\n",
    "\n",
    "Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence.\n",
    "\n",
    "Here, we are building a 3 stacked LSTM for the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBTM94rK8UrI",
    "outputId": "32dea27c-399e-4b5d-fe7b-86c14202c20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 35, 100)      1608300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 35, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 35, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    431400      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 35, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 4314)   2592714     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,217,514\n",
      "Trainable params: 7,217,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6MWrvlt8jrk"
   },
   "source": [
    "I am using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly. This overcomes any memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bZ5Hbh_Y8gGA"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "120rqztE8nL-"
   },
   "source": [
    "\n",
    "Remember the concept of early stopping? It is used to stop training the neural network at the right time by monitoring a user-specified metric. Here, I am monitoring the validation loss (val_loss). Our model will stop training once the validation loss increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "aFNGXOrL8phP"
   },
   "outputs": [],
   "source": [
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azH2zKGQ8tjT"
   },
   "source": [
    "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOk9KDx68tTI",
    "outputId": "eecadd7b-d988-4762-e70b-f7b2ba00602b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1084/1084 [==============================] - 627s 568ms/step - loss: 1.3428 - val_loss: 1.0203\n",
      "Epoch 2/50\n",
      "1084/1084 [==============================] - 605s 558ms/step - loss: 0.9977 - val_loss: 0.9448\n",
      "Epoch 3/50\n",
      "1084/1084 [==============================] - 603s 556ms/step - loss: 0.9365 - val_loss: 0.9123\n",
      "Epoch 4/50\n",
      "1084/1084 [==============================] - 606s 559ms/step - loss: 0.9000 - val_loss: 0.8826\n",
      "Epoch 5/50\n",
      "1084/1084 [==============================] - 606s 559ms/step - loss: 0.8676 - val_loss: 0.8646\n",
      "Epoch 6/50\n",
      "1084/1084 [==============================] - 614s 566ms/step - loss: 0.8491 - val_loss: 0.8550\n",
      "Epoch 7/50\n",
      "1084/1084 [==============================] - 609s 562ms/step - loss: 0.8318 - val_loss: 0.8461\n",
      "Epoch 8/50\n",
      "1084/1084 [==============================] - 606s 559ms/step - loss: 0.8185 - val_loss: 0.8319\n",
      "Epoch 9/50\n",
      "1084/1084 [==============================] - 614s 567ms/step - loss: 0.8002 - val_loss: 0.8241\n",
      "Epoch 10/50\n",
      "1084/1084 [==============================] - 619s 572ms/step - loss: 0.7905 - val_loss: 0.8154\n",
      "Epoch 11/50\n",
      "1084/1084 [==============================] - 612s 565ms/step - loss: 0.7791 - val_loss: 0.8132\n",
      "Epoch 12/50\n",
      "1084/1084 [==============================] - 613s 566ms/step - loss: 0.7706 - val_loss: 0.8070\n",
      "Epoch 13/50\n",
      "1084/1084 [==============================] - 610s 563ms/step - loss: 0.7633 - val_loss: 0.8009\n",
      "Epoch 14/50\n",
      "1084/1084 [==============================] - 612s 565ms/step - loss: 0.7542 - val_loss: 0.8018\n",
      "Epoch 15/50\n",
      "1084/1084 [==============================] - 606s 559ms/step - loss: 0.7470 - val_loss: 0.7927\n",
      "Epoch 16/50\n",
      "1084/1084 [==============================] - 602s 555ms/step - loss: 0.7429 - val_loss: 0.7934\n",
      "Epoch 17/50\n",
      "1084/1084 [==============================] - 601s 554ms/step - loss: 0.7358 - val_loss: 0.7900\n",
      "Epoch 18/50\n",
      "1084/1084 [==============================] - 604s 557ms/step - loss: 0.7319 - val_loss: 0.7881\n",
      "Epoch 19/50\n",
      "1084/1084 [==============================] - 612s 565ms/step - loss: 0.7255 - val_loss: 0.7830\n",
      "Epoch 20/50\n",
      "1084/1084 [==============================] - 614s 566ms/step - loss: 0.7185 - val_loss: 0.7850\n",
      "Epoch 21/50\n",
      "1084/1084 [==============================] - 607s 560ms/step - loss: 0.7136 - val_loss: 0.7857\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Lzd3sI_HGf2v",
    "outputId": "c3701a6b-cb34-412e-9595-7261bcdda002"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOdbn1YkGmwI"
   },
   "source": [
    "\n",
    "From the plot, we can infer that validation loss has increased after epoch 19 for 2 successive epochs. Hence, training is stopped at epoch 21.\n",
    "\n",
    "Next, let’s build the dictionary to convert the index to word for target and source vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "m8SOiMDjGna4"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iryhk5O5GqZo"
   },
   "source": [
    "\n",
    "# Inference\n",
    "Set up the inference for the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dhEKL4yQGtX7"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaCuFVGaGy_g"
   },
   "source": [
    "\n",
    "We are defining a function below which is the implementation of the inference process (which we covered here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "vUm-9AUHGxQN"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai0626tRG3El"
   },
   "source": [
    "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tpEqcVTNG5VT"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5on-8Vx2G745"
   },
   "source": [
    "\n",
    "Here are a few summaries generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsTesZtSG9qn",
    "outputId": "346ab86f-edc4-46ca-801d-174e9be6879c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: muir glen makes best canned tomatoes tasted ripe firm hold shape better canned tomatoes fire roasted ones delicious smoky flavour reminiscent hot paprika excellent recipe requiring little extra zing \n",
      "Original summary: the most canned tomatoes \n",
      "Predicted summary:  best canned food\n",
      "\n",
      "\n",
      "Review: yummy alternative crackers great everything chicken salad mores \n",
      "Original summary: delicious \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: husband loves cheese snacks tried flavored ones prefers plain cheese ones handy take car brief case highly recommends \n",
      "Original summary: easy quick snack \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: favorite green tea flavor bar none celestial seasonings good ones one tops list complaint celestial seasonings changed art box show amazon new picture nowhere near good \n",
      "Original summary: good stuff \n",
      "Predicted summary:  not the same as the original\n",
      "\n",
      "\n",
      "Review: since hard find picture laces store happy find could get online order painless sent right away thought shipping costs little high quality laces everything looking would order kenny \n",
      "Original summary: licorice \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: give seems three dogs tell yes bit pricey smell appealing dogs love worth certainly seem listen better treats \n",
      "Original summary: give me more \n",
      "Predicted summary:  dogs love them\n",
      "\n",
      "\n",
      "Review: love tea drink every morning suppose benefits lowering blood pressure sure put little agave enjoy coffee get heart burn upset stomach \n",
      "Original summary: love this tea \n",
      "Predicted summary:  love this tea\n",
      "\n",
      "\n",
      "Review: nice big juicy flavor texture good sometimes stick together wish individually wrapped overall good product \n",
      "Original summary: good very tasty \n",
      "Predicted summary:  good flavor\n",
      "\n",
      "\n",
      "Review: think tried every bloody mary mixer market one time much sugar worst corn syrup mixer natural ingredients tasty little kick enjoy \n",
      "Original summary: best bloody mary mixer \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: go anywhere without mints far convenient big altoids carry everywhere order case came fast reorder often \n",
      "Original summary: do not leave home without them \n",
      "Predicted summary:  love this mints\n",
      "\n",
      "\n",
      "Review: two lb powerful chewers love rings sit hours gnawing replace twice actually chewed ring sharp circle great holding paws chewing dangling mouth chew back teeth guy highly recommended \n",
      "Original summary: powerful chewers love these \n",
      "Predicted summary:  great toy\n",
      "\n",
      "\n",
      "Review: chai perfect perfect blend sweet little kick spice chai teas spice real flavor mild love much automatic order amazon every months \n",
      "Original summary: absolutely amazing \n",
      "Predicted summary:  best chai tea\n",
      "\n",
      "\n",
      "Review: say love peanuts love regular kinds filling tasty got one gumball machines filled love go \n",
      "Original summary: classic \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: like product well really tangy hurt stomach little surprised picky eater yr olds ate sticks one sitting guess labeled kids \n",
      "Original summary: yr olds ate the entire box \n",
      "Predicted summary:  baby liked it but\n",
      "\n",
      "\n",
      "Review: delicious favorite flavor really taste like chocolate covered pretzels sugar per bar definitely worth money healthy snack \n",
      "Original summary: tastes like chocolate covered pretzels \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: service dog loves treats large enough easily smaller pieces natural goes nuts \n",
      "Original summary: great treat for any dog \n",
      "Predicted summary:  dog loves them\n",
      "\n",
      "\n",
      "Review: bought almond flavor wow seriously best tasting wafer snacks ever tasted love cannot wait try flavors \n",
      "Original summary: best tasting wafers \n",
      "Predicted summary:  best tasting wafers\n",
      "\n",
      "\n",
      "Review: awesome good boot sure probably little much salt everything moderation right \n",
      "Original summary: wicked good \n",
      "Predicted summary:  wicked good\n",
      "\n",
      "\n",
      "Review: twisted fruit sweet taste kids love pop thier lunchbox feel good plus open package ease \n",
      "Original summary: good \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: tried every brand stevia market hands best use nu naturals nustevia sweetening purposes hard find even health food stores ones carry usually charge premium delighted find amazon com reasonable price even less obtained standing order \n",
      "Original summary: perfectly naturally sweet \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: become big fan whole grain kashi cereals particular kashi bars bit dry dark chocolate coconut standby go granola bar dark chocolate icing soft coconut make bar decadent delight remaining reasonably healthy bar really tough beat \n",
      "Original summary: the best kashi fruit and grain bar easily \n",
      "Predicted summary:  my favorite\n",
      "\n",
      "\n",
      "Review: get best products company huge selection difficult find herbs fresh fragrant well preserved inexpensive cook \n",
      "Original summary: good products \n",
      "Predicted summary:  great quality\n",
      "\n",
      "\n",
      "Review: product adds flavor otherwise lack luster recipies low sodium diet must cost one gets return highly recommend product healthy delicious food get use product \n",
      "Original summary: healthy tasty \n",
      "Predicted summary:  excellent product\n",
      "\n",
      "\n",
      "Review: yep quite true never met carmel like admitted also say kraft caramels favorites perfect baking like tuck one lunch box school treat reservation wish would produce salted caramel really tasty \n",
      "Original summary: never met caramel did not like \n",
      "Predicted summary:  amazing\n",
      "\n",
      "\n",
      "Review: google coconut oil found great health based review gave nutiva try never regret smalls good put one jar little kitchen another one bathroom besides cooking use hair best ever loves \n",
      "Original summary: smells great works great \n",
      "Predicted summary:  great for cooking\n",
      "\n",
      "\n",
      "Review: mix tastes terrible waste money sad hard get good gluten free bread costs much average bread disappointed \n",
      "Original summary: terrible garbanzo bean aftertaste \n",
      "Predicted summary:  yuck\n",
      "\n",
      "\n",
      "Review: caramels arrived quickly soft unwrapped seems like fresh disappointed would bought known would fresh \n",
      "Original summary: caramels not fresh \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: loacker products excellent expensive got bag deli corner st rd ave manhattan believe amazon use plus shipping rip \n",
      "Original summary: too expensive \n",
      "Predicted summary:  price\n",
      "\n",
      "\n",
      "Review: thought maybe employee dumped chewing tobacco mix spit mouth bad \n",
      "Original summary: tastes like chewing \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: ok cant quite explain reason girlfriend thinks tea greatest earl grey currently made ive actually bought years supply every christmas past years \n",
      "Original summary: great tea great company \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: love cheap value pack even though tea seem help increase milk supply still like drinking since go bunch hated make trip specialty store every week large shipment amount low price happy \n",
      "Original summary: great value but have not seen an improvement \n",
      "Predicted summary:  great tea but cheaper at local store\n",
      "\n",
      "\n",
      "Review: household ferrero rocher go quickly quicker gourmet chocolate stuff good bucks bought cannot beat \n",
      "Original summary: chocolates \n",
      "Predicted summary:  great value\n",
      "\n",
      "\n",
      "Review: bought along salmon furikake reviewers right wasabi seasoning spicy still like though seasoning give tear inducing experience eating wasabi eat pre cooked brown rice healthy meal much better staple college students ramen noodles \n",
      "Original summary: good stuff \n",
      "Predicted summary:  wow\n",
      "\n",
      "\n",
      "Review: pack almond extract excellent value however bubble wrap packing material way flimsy first order completely smashed vendor extremely helpful getting replacement shipment \n",
      "Original summary: great value \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: buy office put candy machine brookstone partners love \n",
      "Original summary: love em \n",
      "Predicted summary:  love em\n",
      "\n",
      "\n",
      "Review: tastes great wife drink tea occasion regular grocery stores dont usually stock \n",
      "Original summary: taste \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: awful love vanilla nuts looking forward tea tastes artificial medicine like price per box good compared store price certain stash flavors stores worth \n",
      "Original summary: decaf vanilla nut creme tea review \n",
      "Predicted summary:  too much sugar\n",
      "\n",
      "\n",
      "Review: month old pomeranian loves also handy since small treats break \n",
      "Original summary: my puppy loves these \n",
      "Predicted summary:  my dog loves these\n",
      "\n",
      "\n",
      "Review: great price excellent chip cents ounce bag bargain well tasty chip everyone let try impressed commented good taste yet find kettle chip disappointed \n",
      "Original summary: tasty \n",
      "Predicted summary:  great deal\n",
      "\n",
      "\n",
      "Review: live hawaii crave sourdough bread mix works well bread maker oven delicious flavor right texture subscribing future orders \n",
      "Original summary: great bread mix \n",
      "Predicted summary:  delicious bread\n",
      "\n",
      "\n",
      "Review: frequently eat popchips sandwich lunch avid weight watchers lifetime member enjoy without guilt weight watchers friendly love healthy alternative regular chips yet satisfy craving salty \n",
      "Original summary: healthy tasty and weight watchers friendly \n",
      "Predicted summary:  popchips\n",
      "\n",
      "\n",
      "Review: purchased past order tasted little stale purchased food many times first time disappointed quality returned \n",
      "Original summary: tasted funny \n",
      "Predicted summary:  stale\n",
      "\n",
      "\n",
      "Review: must say put life back dog old offers vitamins minerals getting food energy begs choco drops \n",
      "Original summary: is the best \n",
      "Predicted summary:  great for your dog\n",
      "\n",
      "\n",
      "Review: love dark chocolate recently decided eat sugar delighted find dark chocolate cordial cherries taste indistinguishable real thing course one must exercise consuming artificial sweeteners want dark chocolately treat really fill bill highly recommend \n",
      "Original summary: absolutely delicious \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: enjoy chips got instead usual jalapeno ones company bit flavor change think better slightly like jalapenos great amount flavor without overpowering small bag size prevents overeating larger bag \n",
      "Original summary: quite good \n",
      "Predicted summary:  quite good\n",
      "\n",
      "\n",
      "Review: spread better nutella less sweet smooth peanut butter consistency unlike brand find sweet syrup like great cocoa flavor price great \n",
      "Original summary: smooth and delicious \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: coffee surprisingly delicious never problem cups bursting maybe defect coffee brewer coffee bit less strong normally prefer coffee makes great taste look forward mug every morning would definitely recommend buy \n",
      "Original summary: yummy hazelnut \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: chai latte far better designer drink get coffee shop absolutely hooked anyone friend mine facebook knows always cup chai latte begin writing day bears us \n",
      "Original summary: my absolutely favorite way to start the day \n",
      "Predicted summary:  love this chai\n",
      "\n",
      "\n",
      "Review: great tasting coffee exactly flavor says much flavor perfect great dessert coffee pleased purchase \n",
      "Original summary: yummy \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: cutting back carbs anywhere possibly tried every sugar free syrup one best thick tastes great butter flavor low carbs whether must watch sugar intake health reasons must try \n",
      "Original summary: it is the best \n",
      "Predicted summary:  great sugar free syrup\n",
      "\n",
      "\n",
      "Review: tried many different mint flavored teas bigelow tazo tea favorite mint strong enough play role opening sinuses relaxing \n",
      "Original summary: best mint tea by my \n",
      "Predicted summary:  best mint tea\n",
      "\n",
      "\n",
      "Review: olive oil potato chips hard find area delighted find quite reasonable price via amazon tasty crisp salted perfection sea salt heartily recommend give try disappointed \n",
      "Original summary: yum \n",
      "Predicted summary:  great chips\n",
      "\n",
      "\n",
      "Review: great gum place still buy glad find \n",
      "Original summary: gum \n",
      "Predicted summary:  great gum\n",
      "\n",
      "\n",
      "Review: even know start horrible texture grainy sweet flavor really chocolate live far store would back say overpriced would even try flavors yuck \n",
      "Original summary: omg yuck \n",
      "Predicted summary:  horrible\n",
      "\n",
      "\n",
      "Review: texture food like cooled pea soup stiff pate style foods cat likes veggies leaves veggies lot also good bit chicken surrounding makes waste willing tolerate buying spot stew \n",
      "Original summary: wish they would the veggies \n",
      "Predicted summary:  my cat loves it\n",
      "\n",
      "\n",
      "Review: love clever design keeps dogs busy quite perfect bored dogs cold december day \n",
      "Original summary: perfect \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: basis diet using zesty italian little oil still get great taste \n",
      "Original summary: fantastic \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: asin pa green mountain coffee pumpkin spice cup packs keurig brewers count great flavor thought would drink cold winter months wrong great anytime \n",
      "Original summary: treat anytime of the year \n",
      "Predicted summary:  great flavor\n",
      "\n",
      "\n",
      "Review: male van picky litter ever since started using regularly one single accident surface box great litter great price \n",
      "Original summary: nice to have litter delivered to your door \n",
      "Predicted summary:  great for espresso\n",
      "\n",
      "\n",
      "Review: friend recommended buy month old could find grocery store ordered online amazon bit nervous order whole case great decision loves keep busy quiet sometimes minutes time awesome treat baby love organic \n",
      "Original summary: love them \n",
      "Predicted summary:  love these\n",
      "\n",
      "\n",
      "Review: pleasantly surprised thirst quenching love felt consuming product tea products left feeling strange afterwards tea grab certain great drink experience \n",
      "Original summary: what great tea experience \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: love products love idea behind fact help animals cancer zukes president please \n",
      "Original summary: zukes \n",
      "Predicted summary:  my picky eater loves this\n",
      "\n",
      "\n",
      "Review: smell alone make salivate good comes rock sugar mixed ever use added sweeteners \n",
      "Original summary: delicious \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: typically prefer espresso drink coffee beverages however laws bought keurig decided start drinking regular coffee enjoy breakfast blend rich smooth coffee without acidic make iced coffee get watered lose flavor \n",
      "Original summary: the best cup of coffee that have brewed at home \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: bad food worth increased price time find something different recommendations welcomed tired paying less \n",
      "Original summary: price went up and it wasnt worth the original price \n",
      "Predicted summary:  too expensive\n",
      "\n",
      "\n",
      "Review: parents sent care package deployed amazing much better nature bars \n",
      "Original summary: these are geat \n",
      "Predicted summary:  these are great\n",
      "\n",
      "\n",
      "Review: cereal new york city around box bought six pack ended paying around box def well worth purchase also love frosted shredded wheat \n",
      "Original summary: great price for cereal \n",
      "Predicted summary:  great cereal\n",
      "\n",
      "\n",
      "Review: treats fit lab treat ball could longer find local stores thank goodness amazon since prime members ship free get days deal \n",
      "Original summary: right size \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: taste weak improve coffee creamer sorry box dud wish could return \n",
      "Original summary: weak \n",
      "Predicted summary:  weak\n",
      "\n",
      "\n",
      "Review: far favorite olive excellent dips dressings \n",
      "Original summary: best olive oil ever \n",
      "Predicted summary:  best olive oil ever\n",
      "\n",
      "\n",
      "Review: box pomegranate blueberry pistachio antioxidants delicious kind bar products great choice balanced satisfying nutritious bar low sodium without gluten love kind bars definitely back pack boxes amazon great value \n",
      "Original summary: kind bars are the best \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: adopted dog rescue shelter allergy corn live small town found dog food contain mainly corn perfect new pet well loves added bonus comes straight door \n",
      "Original summary: for dogs with special needs \n",
      "Predicted summary:  healthy treat\n",
      "\n",
      "\n",
      "Review: two dogs quite expensive dingo habit always looking less expensive mini dingos great price ordering receipt product exceeded expectations \n",
      "Original summary: perfect \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: tried lots gf pastas favorite sure comments mushy come never problem advice best find store try buy packages worried \n",
      "Original summary: winner in our house \n",
      "Predicted summary:  best gf pasta\n",
      "\n",
      "\n",
      "Review: enjoy different foods regular salt regular shaker like spice things differently may \n",
      "Original summary: different \n",
      "Predicted summary:  good salt\n",
      "\n",
      "\n",
      "Review: good last drop wife drink weeks thats cups guess good guess get \n",
      "Original summary: great coffee \n",
      "Predicted summary:  good coffee\n",
      "\n",
      "\n",
      "Review: weight watcher leader recommend product members still points plus light crispy tasty many flavors great meal evening snack glad discovered \n",
      "Original summary: awesome snacking \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: seeds hobby knife left water night placed moist paper inside ziplock bag days nearly sprouted \n",
      "Original summary: sprouted quickly \n",
      "Predicted summary:  not as described\n",
      "\n",
      "\n",
      "Review: dont much becuase makes poop day awesome detox sometimes makes nausous good tasts good \n",
      "Original summary: this works \n",
      "Predicted summary:  it works\n",
      "\n",
      "\n",
      "Review: although believe helps weight loss great flavor husband normally drink hot tea loves \n",
      "Original summary: good flavor \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n",
      "Review: better bowls sugar free instant chocolate pudding delicious diabetic celiac disease looking something sugar free without also gluten free difficult find better bowls fit needs perfectly delicious thank better bowls wonderful product \n",
      "Original summary: healthy and delicious \n",
      "Predicted summary:  great sugar free chocolate\n",
      "\n",
      "\n",
      "Review: wonderful texture great taste thank mrs weiss helping remember grandma cooking \n",
      "Original summary: almost as good as my grandma homemade noodles \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: siberian loves food tried fish kind well orijen although cat loved taste smell enough keep away continue buy food kitty coat gorgeous hairballs compact stools kibble food love orijen \n",
      "Original summary: best food ever \n",
      "Predicted summary:  great food\n",
      "\n",
      "\n",
      "Review: used buy individual packages servings really glad find canister add coffee instead water morning make low carb high protein cafe mocha little diet taste bad sure stir thoroughly fork also add chocolate smoothies blender \n",
      "Original summary: great value \n",
      "Predicted summary:  great for protein\n",
      "\n",
      "\n",
      "Review: older lhasa apso fussy eater want dog foods rated good went line searched healthy food tried tried hills loves begs thank hills making great dog food \n",
      "Original summary: my dog loves it \n",
      "Predicted summary:  my dog loves this treat\n",
      "\n",
      "\n",
      "Review: wish noticed list ingredients purchased product cheese read ingredients msg bad ingredients besides cheese yuck throw taste great either \n",
      "Original summary: not that great \n",
      "Predicted summary:  not as good as the original\n",
      "\n",
      "\n",
      "Review: always make anything bake shopping costco one day saw product since chili night dinner thought would try great product today go get costco went line ordered love left great morning coffee \n",
      "Original summary: absolutely delicious \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: fairly expensive item kitty loves ofcourse plain old taste good eating treats \n",
      "Original summary: kitty loves \n",
      "Predicted summary:  cat loves these\n",
      "\n",
      "\n",
      "Review: sam sale thsi product per count purchase per count plus freight \n",
      "Original summary: cost to high \n",
      "Predicted summary:  price\n",
      "\n",
      "\n",
      "Review: favorite coffee like strongly flavored brew fills bill smokey flavor enhancement like \n",
      "Original summary: my favorite coffee \n",
      "Predicted summary:  love this coffee\n",
      "\n",
      "\n",
      "Review: tried several disc coffees sold tassimo feel coffee best tasting strong smooth bitter tasting \n",
      "Original summary: delicious non bitter coffee \n",
      "Predicted summary:  best coffee ever\n",
      "\n",
      "\n",
      "Review: buy item auto ship last order found inner package cereal properly sealed one corners open inches called kashi gave information box sent coupon replacement box good customer service buys stay amazon needs whatever \n",
      "Original summary: kashi customer service \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: best peanut butter ever crunchy wish came large size \n",
      "Original summary: skippy peanut butter \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: replace starbucks caramel mocha get morning flavored coffee bp qt great replacement \n",
      "Original summary: saves stop to the gas station in the mornings \n",
      "Predicted summary:  coffee\n",
      "\n",
      "\n",
      "Review: still great reordered increase since may nuts product good wow good love place find stores changing versions something good change long shelf life never make \n",
      "Original summary: great but as of \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: product really goes well toddlers eat could give pediasure doubt even close organic product really got toddlers health track thanks orgain btw bought wegmans \n",
      "Original summary: great for picky toddlers with picky moms \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: ok quick meal found meat bit dry lacking flavor gravy ok potatoes ok bad good items line \n",
      "Original summary: ok not bad not great \n",
      "Predicted summary:  ok but not great\n",
      "\n",
      "\n",
      "Review: cups came bloated looking like inflated marshmallows even begin fit machine \n",
      "Original summary: cups \n",
      "Predicted summary:  cups\n",
      "\n",
      "\n",
      "Review: cats love whiskers temptation treats amazon place find five cats much convenient hairball gel \n",
      "Original summary: hairball treats \n",
      "Predicted summary:  cats love it\n",
      "\n",
      "\n",
      "Review: dog seems like better deer feed vet price half seems itching less \n",
      "Original summary: good stuff \n",
      "Predicted summary:  good dog food\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "abstractive summarisation250k(lstm,attention).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
